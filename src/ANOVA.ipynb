{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_classe0 0.43524117082845076\n",
      "recall_classe0 0.22515634682184826\n",
      "f1-score_classe0 0.20389015575834032\n",
      "precision_classe1 0.9030845527913003\n",
      "recall_classe1 0.09170896112652814\n",
      "f1-score_classe1 0.23366649543245685\n",
      "precision_classe2 0.22880735568437582\n",
      "recall_classe2 0.7084429946684162\n",
      "f1-score_classe2 0.42308387355999655\n",
      "precision_classe3 0.49524953130544047\n",
      "recall_classe3 0.5273138172108863\n",
      "f1-score_classe3 0.017163637419089398\n",
      "A métrica 'f1-score_classe3' apresenta uma diferença significativa entre os modelos.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "\n",
    "def perform_anova(csv_file1, csv_file2):\n",
    "    # Leitura dos arquivos CSV\n",
    "    df1 = pd.read_csv(csv_file1)\n",
    "    df2 = pd.read_csv(csv_file2)\n",
    "\n",
    "    anova_results = {}\n",
    "    for (index_1, row_1), (index_2, row_2) in zip(df1.iterrows(), df2.iterrows()):\n",
    "        \n",
    "        assert row_1[\"Metrica\"] == row_2[\"Metrica\"]\n",
    "        data1 = [\n",
    "            row_1[\"Fold1\"],\n",
    "            row_1[\"Fold2\"],\n",
    "            row_1[\"Fold3\"],\n",
    "            row_1[\"Fold4\"],\n",
    "            row_1[\"Fold5\"],\n",
    "        ]\n",
    "        data2 = [\n",
    "            row_2[\"Fold1\"],\n",
    "            row_2[\"Fold2\"],\n",
    "            row_2[\"Fold3\"],\n",
    "            row_2[\"Fold4\"],\n",
    "            row_2[\"Fold5\"],\n",
    "        ]\n",
    "\n",
    "        # Executa a análise ANOVA\n",
    "        if (\"support\" in row_1[\"Metrica\"]) or (\"support\" in row_2[\"Metrica\"]):\n",
    "            continue\n",
    "\n",
    "        statistic, p_value = f_oneway(data1, data2)\n",
    "        # Armazena o resultado da ANOVA\n",
    "        anova_results[row_1[\"Metrica\"]] = p_value\n",
    "\n",
    "    return anova_results\n",
    "\n",
    "\n",
    "def compare_models(csv_file1, csv_file2):\n",
    "    # Chamar a função perform_anova para obter os resultados da ANOVA\n",
    "    anova_results = perform_anova(csv_file1, csv_file2)\n",
    "\n",
    "    # Verificar o valor de p para cada métrica e identificar a melhor métrica ou se não há diferença significativa\n",
    "    best_metric = None\n",
    "    for metric, p_value in anova_results.items():\n",
    "        print(metric, p_value)\n",
    "        if p_value < 0.05:\n",
    "            if best_metric is None or p_value < anova_results[best_metric]:\n",
    "                best_metric = metric\n",
    "\n",
    "    if best_metric is not None:\n",
    "        print(\n",
    "            f\"A métrica '{best_metric}' apresenta uma diferença significativa entre os modelos.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"Não há diferença significativa entre os modelos.\")\n",
    "\n",
    "\n",
    "# Exemplo de uso\n",
    "csv_file1 = \"metrics_mobilenet.csv\"\n",
    "csv_file2 = \"metrics_resnet152.csv\"\n",
    "\n",
    "compare_models(csv_file1, csv_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
